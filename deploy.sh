#!/bin/bash

# Master Deployment Script for Digital Ocean Droplet
# This handles all deployment, initialization, and setup
# Usage: ./deploy.sh

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

echo "======================================"
echo "üöÄ Auto-Ops-AI Complete Deployment"
echo "======================================"

# Export environment variables
export DOCKER_HUB_USERNAME="${DOCKER_HUB_USERNAME:-}"
export DOCKER_HUB_PASSWORD="${DOCKER_HUB_PASSWORD:-}"
export GOOGLE_API_KEY="${GOOGLE_API_KEY:-}"

# Get public IP address (try multiple methods for reliability)
DROPLET_IP=""
if [ -z "$DROPLET_IP" ]; then
    # Try to get public IP from metadata (DigitalOcean)
    DROPLET_IP=$(curl -s http://169.254.169.254/metadata/v1/public-ipv4 2>/dev/null || true)
fi
if [ -z "$DROPLET_IP" ]; then
    # Fallback: use first non-loopback IP
    DROPLET_IP=$(hostname -I | awk '{for(i=1;i<=NF;i++) if($i !~ /^127\./) {print $i; break}}')
fi
if [ -z "$DROPLET_IP" ]; then
    # Last resort: use localhost (for local testing)
    DROPLET_IP="localhost"
fi

export DROPLET_IP

if [ -z "$DOCKER_HUB_USERNAME" ]; then
    echo "‚ùå Error: DOCKER_HUB_USERNAME not set"
    exit 1
fi

if [ -z "$GOOGLE_API_KEY" ]; then
    echo "‚ö†Ô∏è  Warning: GOOGLE_API_KEY not set - bot will not function"
    echo "   Please add GOOGLE_API_KEY secret to GitHub repository settings"
    echo ""
    echo "   Steps to fix:"
    echo "   1. Go to: https://github.com/gimhanadeshan/auto-ops-ai"
    echo "   2. Settings > Secrets and variables > Actions"
    echo "   3. Click 'New repository secret'"
    echo "   4. Name: GOOGLE_API_KEY"
    echo "   5. Value: Your actual API key from https://makersuite.google.com/app/apikey"
    echo "   6. Click 'Add secret'"
    echo "   7. Push a commit to trigger deployment"
fi

echo "üìç Droplet IP: $DROPLET_IP"
echo "üê≥ Docker Hub User: $DOCKER_HUB_USERNAME"
echo ""
echo "‚ö†Ô∏è  DATA PRESERVATION:"
echo "   ‚Ä¢ Database is stored in 'backend-data' volume (persists across deployments)"
echo "   ‚Ä¢ Logs are stored in 'logs' volume (persists across deployments)"
echo "   ‚Ä¢ Your data will NOT be reset during redeployment"
echo ""

# Step 1: Ensure tools are installed
echo ""
echo "1Ô∏è‚É£  Checking Docker installation..."
if ! command -v docker &> /dev/null; then
    echo "‚ùå Docker not found. Installing..."
    curl -fsSL https://get.docker.com -o get-docker.sh
    sudo sh get-docker.sh
    rm get-docker.sh
fi

if ! command -v docker-compose &> /dev/null; then
    echo "‚ùå docker-compose not found. Installing..."
    sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    sudo chmod +x /usr/local/bin/docker-compose
fi

echo "‚úÖ Docker tools ready"

# Step 2: Prepare application directory
echo ""
echo "2Ô∏è‚É£  Preparing /app directory..."
mkdir -p /app
cd /app

# Step 3: Clone/update repository (with retry)
echo ""
echo "3Ô∏è‚É£  Cloning repository..."
REBUILD_NEEDED=false
DOCKERFILE_CHANGED=false
GIT_RETRY=0
GIT_MAX_RETRIES=2

while [ $GIT_RETRY -lt $GIT_MAX_RETRIES ]; do
    if [ ! -d .git ]; then
        if git clone https://github.com/gimhanadeshan/auto-ops-ai.git . 2>/dev/null; then
            REBUILD_NEEDED=true
            break
        fi
    else
        # Check if there are new changes
        PREV_COMMIT=$(git rev-parse HEAD 2>/dev/null || echo "")
        if git fetch origin main 2>/dev/null; then
            LOCAL=$(git rev-parse HEAD)
            REMOTE=$(git rev-parse origin/main)
            
            if [ "$LOCAL" != "$REMOTE" ]; then
                echo "üìù Code changes detected"
                # Check if Dockerfile was changed
                if git diff $LOCAL $REMOTE --name-only | grep -q "Dockerfile"; then
                    echo "‚ö†Ô∏è  Dockerfile changed - will rebuild all images"
                    DOCKERFILE_CHANGED=true
                    REBUILD_NEEDED=true
                else
                    echo "üìù Other changes detected - will rebuild images"
                    REBUILD_NEEDED=true
                fi
                git checkout -f origin/main
            else
                echo "‚úì Code is up-to-date - using cached images"
                REBUILD_NEEDED=false
            fi
            break
        fi
    fi
    
    GIT_RETRY=$((GIT_RETRY + 1))
    if [ $GIT_RETRY -lt $GIT_MAX_RETRIES ]; then
        echo "‚ö†Ô∏è  Git operation failed (attempt $GIT_RETRY/$GIT_MAX_RETRIES) - retrying in 5 seconds..."
        sleep 5
    else
        echo "‚ùå Git operation failed after $GIT_MAX_RETRIES attempts"
        exit 1
    fi
done

echo "‚úÖ Repository updated"

# Step 4: Create environment files
echo ""
echo "4Ô∏è‚É£  Creating environment configuration files..."

# Create backend .env
mkdir -p backend
cat > backend/.env << EOF
# Auto-generated by deploy.sh
LLM_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
GOOGLE_API_KEY=${GOOGLE_API_KEY}
GEMINI_MODEL=models/gemini-2.5-flash
GEMINI_TEMPERATURE=0.9
EMBEDDING_MODEL=models/embedding-001
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4
DATABASE_URL=sqlite:///./data/processed/auto_ops.db
SECRET_KEY=auto-ops-ai-secret-key-change-in-production
ENVIRONMENT=production
EOF

# Validate GOOGLE_API_KEY was written correctly
if grep -q "^GOOGLE_API_KEY=$" backend/.env; then
    echo "‚ùå ERROR: GOOGLE_API_KEY is empty in production .env"
    echo "   Bot will NOT function in production"
    echo "   Please verify GitHub Secret is set and deployment includes GOOGLE_API_KEY"
    exit 1
elif grep -q "^GOOGLE_API_KEY=" backend/.env; then
    echo "‚úÖ Backend .env created with API key"
else
    echo "‚ö†Ô∏è  Warning: Could not verify GOOGLE_API_KEY in .env"
fi

# Create frontend .env
mkdir -p frontend
cat > frontend/.env << EOF
# Auto-generated by deploy.sh
VITE_API_BASE_URL=http://${DROPLET_IP}:8000/api/v1
EOF
echo "‚úÖ Frontend .env created"

# Step 5: Login to Docker Hub (with retry)
echo ""
echo "5Ô∏è‚É£  Logging in to Docker Hub..."
MAX_RETRIES=2
RETRY_COUNT=0

while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
    if echo "$DOCKER_HUB_PASSWORD" | docker login -u "$DOCKER_HUB_USERNAME" --password-stdin 2>/dev/null; then
        echo "‚úÖ Docker Hub login successful"
        break
    else
        RETRY_COUNT=$((RETRY_COUNT + 1))
        if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
            echo "‚ö†Ô∏è  Docker Hub login failed (attempt $RETRY_COUNT/$MAX_RETRIES), retrying in 3 seconds..."
            sleep 3
        else
            echo "‚ö†Ô∏è  Docker Hub login failed - will build from source"
            REBUILD_NEEDED=true
        fi
    fi
done

# Step 6: Pull latest images or build if changes detected
echo ""
echo "6Ô∏è‚É£  Processing Docker images..."

if [ "$REBUILD_NEEDED" = true ]; then
    echo "üî® Building new images from source..."
    if docker-compose -f docker-compose.deploy.yml build --no-cache 2>/dev/null; then
        echo "‚úÖ Images built successfully"
    else
        echo "‚ùå Build failed - checking if images exist locally..."
        BACKEND_IMAGE=$(docker images | grep auto-ops-ai-backend | head -1 | awk '{print $3}')
        FRONTEND_IMAGE=$(docker images | grep auto-ops-ai-frontend | head -1 | awk '{print $3}')
        if [ -n "$BACKEND_IMAGE" ] && [ -n "$FRONTEND_IMAGE" ]; then
            echo "‚úÖ Using existing local images"
        else
            echo "‚ùå No images available - deployment cannot continue"
            exit 1
        fi
    fi
else
    echo "üì¶ Checking for pre-built images..."
    
    # Try to pull with retry logic
    PULL_RETRY=0
    while [ $PULL_RETRY -lt 2 ]; do
        if docker pull $DOCKER_HUB_USERNAME/auto-ops-ai-backend:latest 2>/dev/null && \
           docker pull $DOCKER_HUB_USERNAME/auto-ops-ai-frontend:latest 2>/dev/null; then
            echo "‚úÖ Images pulled successfully"
            break
        else
            PULL_RETRY=$((PULL_RETRY + 1))
            if [ $PULL_RETRY -lt 2 ]; then
                echo "‚ö†Ô∏è  Pull failed (attempt $PULL_RETRY/2) - checking for local images..."
            else
                echo "‚ö†Ô∏è  Cannot pull from Docker Hub - using local images if available"
            fi
        fi
    done
    
    # Check if local images exist
    BACKEND_IMAGE=$(docker images | grep auto-ops-ai-backend | head -1 | awk '{print $3}')
    if [ -z "$BACKEND_IMAGE" ]; then
        echo "‚ö†Ô∏è  Local images not found - will build from source"
        if docker-compose -f docker-compose.deploy.yml build --no-cache 2>/dev/null; then
            echo "‚úÖ Images built successfully"
        else
            echo "‚ùå Build failed and no images available"
            exit 1
        fi
    fi
fi

# Step 7: Stop old containers
echo ""
echo "7Ô∏è‚É£  Stopping old containers..."
docker-compose -f docker-compose.deploy.yml down || true
echo "‚úÖ Old containers stopped"

# Step 8: Start new containers
echo ""
echo "8Ô∏è‚É£  Starting new containers..."
docker-compose -f docker-compose.deploy.yml up -d
echo "‚úÖ Containers started"

# Step 9: Open firewall ports
echo ""
echo "9Ô∏è‚É£  Configuring firewall..."
ufw allow 8000/tcp || true
ufw allow 80/tcp || true
ufw allow 443/tcp || true
echo "‚úÖ Firewall configured"

# Step 10: Wait for services with health check
echo ""
echo "üîü Waiting for backend to be ready..."
HEALTH_WAIT=0
MAX_WAIT=30
while [ $HEALTH_WAIT -lt $MAX_WAIT ]; do
    if curl -s http://localhost:8000/health > /dev/null 2>&1; then
        echo "‚úÖ Backend is ready!"
        break
    fi
    HEALTH_WAIT=$((HEALTH_WAIT + 5))
    if [ $HEALTH_WAIT -lt $MAX_WAIT ]; then
        echo "  ‚è≥ Waiting... ($HEALTH_WAIT/$MAX_WAIT seconds)"
        sleep 5
    fi
done

if [ $HEALTH_WAIT -ge $MAX_WAIT ]; then
    echo "‚ö†Ô∏è  Backend didn't respond to health check (normal for first deployment)"
fi

# Step 11: Initialize database (skip if already exists)
echo ""
echo "1Ô∏è‚É£1Ô∏è‚É£ Checking database status..."
# Step 10: Check database and initialize if needed
echo ""
echo "1Ô∏è‚É£0Ô∏è‚É£ Checking database persistence..."

# Show current volume status
echo "üìÅ Database volumes in use:"
docker volume ls | grep backend-data || echo "   No volumes found yet"

DB_PATH="/app/data/processed/auto_ops.db"

# Check if database exists inside the container
DB_EXISTS=$(docker-compose -f docker-compose.deploy.yml exec -T backend sh -c "[ -f $DB_PATH ] && echo '1' || echo '0'" 2>/dev/null || echo "0")

if [ "$DB_EXISTS" = "1" ]; then
    echo "‚úÖ Database file exists (data preserved)"
else
    echo "üîÑ Database not found - initializing..."
    echo "   [i] This is expected on first deployment"
    if docker-compose -f docker-compose.deploy.yml exec -T backend python init_db.py; then
        echo "‚úÖ Database initialized successfully"
    else
        echo "‚ùå Database initialization failed"
        exit 1
    fi
fi

# Step 11b: Check vector database (MOVED AFTER INGESTION)
echo ""
echo "1Ô∏è‚É£1Ô∏è‚É£b Checking vector database (ChromaDB) status..."
VECTOR_DB_PATH="/app/data/processed/chroma_db"
# Will check after ingestion runs

# Step 12: Check admin user and seed data
echo ""
echo "1Ô∏è‚É£2Ô∏è‚É£ Checking admin user..."
ADMIN_EXISTS=$(docker-compose -f docker-compose.deploy.yml exec -T backend python -c "
from app.core.database import SessionLocal
from app.models.user import UserDB
try:
    session = SessionLocal()
    admin = session.query(UserDB).filter(UserDB.email == 'admin@acme.com').first()
    print('1' if admin else '0')
except:
    print('0')
" 2>/dev/null || echo "0")

if [ "$ADMIN_EXISTS" = "1" ]; then
    echo "‚úÖ Admin user exists (admin@acme.com)"
else
    echo "üîÑ Admin user not found - creating via init_db.py..."
    if docker-compose -f docker-compose.deploy.yml exec -T backend python init_db.py; then
        echo "‚úÖ Admin user created successfully"
        echo "   Email: admin@acme.com"
        echo "   Password: admin123"
        ADMIN_EXISTS="1"
    else
        echo "‚ùå Failed to create admin user"
        ADMIN_EXISTS="0"
    fi
fi

# Step 13: Load ingestion data
echo ""
echo "1Ô∏è‚É£3Ô∏è‚É£ Loading ingestion data..."
USERS_COUNT=$(docker-compose -f docker-compose.deploy.yml exec -T backend python -c "
from app.core.database import SessionLocal
from app.models.user import UserDB
try:
    session = SessionLocal()
    count = session.query(UserDB).count()
    print(count)
except:
    print('0')
" 2>/dev/null || echo "0")

if [ "$USERS_COUNT" -gt 1 ]; then
    echo "‚úÖ Seed data already loaded"
else
    echo "üîÑ Loading seed data and creating vector database..."
    if docker-compose -f docker-compose.deploy.yml exec -T backend python ingestion_script.py; then
        echo "‚úÖ Seed data and vector database created successfully"
    else
        echo "‚ö†Ô∏è  Ingestion script had issues (this is often expected for Windows paths)"
    fi
fi

# NOW check vector database after ingestion
echo ""
echo "1Ô∏è‚É£3Ô∏è‚É£b Checking vector database after ingestion..."
VECTOR_EXISTS=$(docker-compose -f docker-compose.deploy.yml exec -T backend sh -c "[ -d $VECTOR_DB_PATH ] && echo '1' || echo '0'" 2>/dev/null || echo "0")

# Step 14: Final verification
echo ""
echo "1Ô∏è‚É£4Ô∏è‚É£ Final verification..."

# Check if backend is healthy
HEALTH_STATUS=$(curl -s http://localhost:8000/health 2>/dev/null | grep -o "healthy" || echo "error")
if [ "$HEALTH_STATUS" = "healthy" ]; then
    echo "‚úÖ Backend health check passed"
else
    echo "‚ö†Ô∏è  Backend not responding yet (still starting)"
fi

# Check container status
echo ""
echo "1Ô∏è‚É£5Ô∏è‚É£ Container status:"
docker-compose -f docker-compose.deploy.yml ps

# Step 16: Verify bot is online by checking status endpoint
echo ""
echo "1Ô∏è‚É£6Ô∏è‚É£ Verifying bot status..."
BOT_STATUS=$(curl -s http://localhost:8000/api/v1/status 2>/dev/null | grep -o '"status":"[^"]*"' | cut -d'"' -f4)
BOT_BOT_STATUS=$(curl -s http://localhost:8000/api/v1/status 2>/dev/null | grep -o '"status":"[^"]*"' | tail -1 | cut -d'"' -f4)

if [ "$BOT_BOT_STATUS" = "online" ]; then
    echo "‚úÖ Bot is ONLINE and ready to chat!"
    CONFIG_OK="true"
else
    echo "‚ö†Ô∏è  Bot status: $BOT_BOT_STATUS (check GOOGLE_API_KEY if offline)"
    # Check if API key is in the .env
    if grep -q "^GOOGLE_API_KEY=AIza" backend/.env 2>/dev/null; then
        echo "   API Key appears to be set in .env"
    else
        echo "   ‚ùå API Key may not be properly configured"
    fi
    CONFIG_OK="false"
fi

# Cleanup
docker logout

echo ""
echo "======================================"
echo "‚úÖ Deployment Complete!"
echo "======================================"
echo ""
echo "üìä Deployment Summary:"
echo "   Code Changes:        $([ "$REBUILD_NEEDED" = true ] && echo "YES - Images rebuilt" || echo "NO - Used cached images")"
echo "   Database:            $([ "$DB_EXISTS" = "1" ] && echo "‚úÖ Created & initialized" || echo "‚ö†Ô∏è  Not found")"
echo "   Vector Database:     $([ "$VECTOR_EXISTS" = "1" ] && echo "‚úÖ Created" || echo "‚ö†Ô∏è  Not created yet")"
echo "   Admin User:          $([ "$ADMIN_EXISTS" = "1" ] && echo "‚úÖ Exists" || echo "‚ùå Not seeded")"
echo "   Backend Health:      $([ "$HEALTH_STATUS" = "healthy" ] && echo "‚úÖ Healthy" || echo "‚ö†Ô∏è  Starting")"
echo ""
echo "üåê Access your application:"
echo "   Frontend:  http://$DROPLET_IP"
echo "   Backend:   http://$DROPLET_IP:8000"
echo "   API Docs:  http://$DROPLET_IP:8000/docs"
echo ""
echo "üîê Default Admin Credentials:"
echo "   Email:    admin@acme.com"
echo "   Password: admin123"
echo ""
echo "üìã View logs:"
echo "   docker-compose -f docker-compose.deploy.yml logs -f"
echo ""
